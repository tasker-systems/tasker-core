# TaskTemplate Configuration - DSL Variant - TAS-125 Checkpoint Yield E2E Testing
#
# Tests handler-driven checkpoint yielding with resumption after transient failure.
# Validates that checkpoint_yield() persists progress and steps resume correctly.
#
# Template: checkpoint_yield_test:1.0.0
# Created: 2025-01-03 (TAS-125 E2E Testing)
#
# Test Pattern:
# 1. analyze_items creates 1 batch (configurable total_items)
# 2. checkpoint_yield_batch processes items, yielding checkpoints every N items
# 3. On transient failure, step resumes from last checkpoint
# 4. aggregate_results collects final output
#
# Configuration (via task context):
#   - total_items: Number of items to process (default: 100)
#   - items_per_checkpoint: Items to process before yielding checkpoint (default: 25)
#   - fail_after_items: Fail after processing this many items (optional)
#   - fail_on_attempt: Only fail on this attempt number (optional, default: 1)
#   - permanent_failure: If true, fail with non-retryable error (default: false)
---
name: checkpoint_yield_test_dsl
namespace_name: python_e2e_checkpoint_yield
version: 1.0.0
description: "E2E test proving TAS-125 handler-driven checkpoint yielding works"
metadata:
  author: TAS-125 Checkpoint Yield Testing
  tags:
    - namespace:checkpoint_yield_testing_dsl
    - pattern:checkpoint_yield
    - type:e2e_test
    - implementation:python
  documentation_url:
  created_at: "2025-01-03T00:00:00Z"
  updated_at: "2025-01-03T00:00:00Z"
  notes: "Validates TAS-125 checkpoint_yield() with FFI persistence and re-dispatch"
task_handler:
  callable: python_ffi_handler_dsl
  initialization:
    test_type: checkpoint_yield
system_dependencies:
  primary: default
  secondary: []
domain_events: []
input_schema:
  type: object
  required: []
  properties:
    test_id:
      type: string
      description: "Optional test identifier for debugging"
    total_items:
      type: integer
      description: "Total items to process (default 100)"
    items_per_checkpoint:
      type: integer
      description: "Items before checkpoint yield (default 25)"
    fail_after_items:
      type: integer
      description: "Optional: fail after this many items"
    fail_on_attempt:
      type: integer
      description: "Only fail on this attempt number (default 1)"
    permanent_failure:
      type: boolean
      description: "If true, fail with non-retryable error"
steps:
  # BATCHABLE STEP: Creates a single batch for testing
  - name: analyze_items_dsl_py
    type: batchable
    description: "Analyzes item count and creates 1 batch for checkpoint testing"
    handler:
      callable: checkpoint_yield_dsl_py.step_handlers.checkpoint_yield_analyzer
      initialization:
        worker_template_name: "checkpoint_yield_batch_dsl_py"
    system_dependency:
    dependencies: []
    retry:
      retryable: true
      max_attempts: 3
      backoff: exponential
      backoff_base_ms: 50
      max_backoff_ms: 200
    timeout_seconds: 30
    publishes_events: []

  # BATCH WORKER TEMPLATE: Processes items with checkpoint yielding
  - name: checkpoint_yield_batch_dsl_py
    type: batch_worker
    description: "Processes batch with TAS-125 checkpoint yields"
    handler:
      callable: checkpoint_yield_dsl_py.step_handlers.checkpoint_yield_worker
      initialization:
        # These can be overridden by task context
        items_per_checkpoint: 25
    system_dependency:
    dependencies:
      - analyze_items_dsl_py
    retry:
      retryable: true
      max_attempts: 3
      backoff: exponential
      backoff_base_ms: 50
      max_backoff_ms: 200
    timeout_seconds: 60
    publishes_events: []
    batch_config:
      batch_size: 100
      parallelism: 1
      cursor_field: "id"
      worker_template: "checkpoint_yield_batch_dsl_py"
      failure_strategy: "fail_fast"

  # DEFERRED CONVERGENCE: Aggregates results from batch worker
  - name: aggregate_results_dsl_py
    type: deferred_convergence
    description: "Aggregates checkpoint yield test results"
    handler:
      callable: checkpoint_yield_dsl_py.step_handlers.checkpoint_yield_aggregator
      initialization: {}
    system_dependency:
    dependencies:
      - checkpoint_yield_batch_dsl_py
    retry:
      retryable: true
      max_attempts: 3
      backoff: exponential
      backoff_base_ms: 50
      max_backoff_ms: 200
    timeout_seconds: 30
    publishes_events: []

environments:
  test:
    steps:
      - name: analyze_items_dsl_py
        timeout_seconds: 10
        retry:
          max_attempts: 3
          backoff_base_ms: 50
          max_backoff_ms: 200
      - name: checkpoint_yield_batch_dsl_py
        timeout_seconds: 30
        retry:
          max_attempts: 3
          backoff_base_ms: 50
          max_backoff_ms: 200
      - name: aggregate_results_dsl_py
        timeout_seconds: 10
        retry:
          max_attempts: 3
          backoff_base_ms: 50
          max_backoff_ms: 200
